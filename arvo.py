#!/usr/bin/env python3
"""
ArvoAI - NLP-powered CLI hosting automation tool
Autodeployment system that analyzes repositories and deploys applications
"""

import sys
import os
import json
import requests
import zipfile
import tempfile
import subprocess
import shutil
import re
from typing import Dict, List, Optional, Tuple
from datetime import datetime
from pathlib import Path
import yaml
import logging


class RepositoryAnalyzer:
    """Analyzes code repositories to extract deployment information"""
    
    def __init__(self):
        self.supported_frameworks = {
            'python': {
                'flask': ['app.py', 'main.py', 'wsgi.py'],
                'django': ['manage.py', 'settings.py'],
                'fastapi': ['main.py', 'app.py'],
                'bottle': ['app.py', 'main.py']
            },
            'nodejs': {
                'express': ['package.json', 'app.js', 'server.js', 'index.js'],
                'nextjs': ['package.json', 'next.config.js'],
                'react': ['package.json', 'src/App.js'],
                'vue': ['package.json', 'src/main.js']
            },
            'java': {
                'spring': ['pom.xml', 'build.gradle'],
                'maven': ['pom.xml'],
                'gradle': ['build.gradle']
            },
            'php': {
                'laravel': ['composer.json', 'artisan'],
                'wordpress': ['wp-config.php'],
                'symfony': ['composer.json']
            }
        }
    
    def download_repository(self, repo_url: str) -> str:
        """Download repository from GitHub or extract from zip file"""
        temp_dir = tempfile.mkdtemp()
        
        if repo_url.endswith('.zip'):
            # Extract zip file
            with zipfile.ZipFile(repo_url, 'r') as zip_ref:
                zip_ref.extractall(temp_dir)
        elif 'github.com' in repo_url:
            # Download from GitHub
            if repo_url.endswith('.git'):
                repo_url = repo_url[:-4]
            
            # Convert GitHub URL to zip download
            if '/archive/' not in repo_url:
                # Try different branch names
                branches = ['main', 'master', 'develop']
                success = False
                
                for branch in branches:
                    try:
                        zip_url = repo_url + f'/archive/{branch}.zip'
                        response = requests.get(zip_url)
                        response.raise_for_status()
                        
                        zip_path = os.path.join(temp_dir, 'repo.zip')
                        with open(zip_path, 'wb') as f:
                            f.write(response.content)
                        
                        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                            zip_ref.extractall(temp_dir)
                        
                        # Remove the zip file
                        os.remove(zip_path)
                        success = True
                        break
                        
                    except Exception as e:
                        continue
                
                if not success:
                    raise Exception(f"Failed to download repository from any branch: {repo_url}")
            else:
                try:
                    response = requests.get(repo_url)
                    response.raise_for_status()
                    
                    zip_path = os.path.join(temp_dir, 'repo.zip')
                    with open(zip_path, 'wb') as f:
                        f.write(response.content)
                    
                    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                        zip_ref.extractall(temp_dir)
                    
                    # Remove the zip file
                    os.remove(zip_path)
                    
                except Exception as e:
                    raise Exception(f"Failed to download repository: {e}")
        else:
            raise Exception("Unsupported repository URL format")
        
        return temp_dir
    
    def _get_actual_repo_path(self, downloaded_path: str) -> str:
        """Find the actual repository path within the downloaded directory"""
        # Sometimes GitHub downloads create a subdirectory like 'repo-main' or 'repo-master'
        # We need to find the actual root of the repository
        
        # Check if there's only one subdirectory - likely the repo
        contents = os.listdir(downloaded_path)
        subdirs = [item for item in contents if os.path.isdir(os.path.join(downloaded_path, item))]
        
        # If there's exactly one directory, it's probably the repo
        if len(subdirs) == 1 and len(contents) == 1:
            potential_repo_path = os.path.join(downloaded_path, subdirs[0])
            # Verify it looks like a repo by checking for common files
            repo_contents = os.listdir(potential_repo_path)
            if any(f in repo_contents for f in ['README.md', 'requirements.txt', 'package.json', '.gitignore', 'app', 'src']):
                return potential_repo_path
        
        # Otherwise, use the downloaded path as-is
        return downloaded_path
    
    def analyze_repository(self, repo_path: str) -> Dict:
        """Analyze repository to determine application type and requirements"""
        # Get the actual repository path (in case of nested extraction)
        actual_repo_path = self._get_actual_repo_path(repo_path)
        
        analysis = {
            'language': None,
            'framework': None,
            'dependencies': [],
            'start_commands': [],
            'port': None,
            'environment_vars': [],
            'build_commands': [],
            'files_to_modify': []
        }
        
        # Check for Python applications
        if self._is_python_app(actual_repo_path):
            analysis.update(self._analyze_python_app(actual_repo_path))
        
        # Check for Node.js applications
        elif self._is_nodejs_app(actual_repo_path):
            analysis.update(self._analyze_nodejs_app(actual_repo_path))
        
        # Check for Java applications
        elif self._is_java_app(actual_repo_path):
            analysis.update(self._analyze_java_app(actual_repo_path))
        
        # Check for PHP applications
        elif self._is_php_app(actual_repo_path):
            analysis.update(self._analyze_php_app(actual_repo_path))
        
        return analysis
    
    def _is_python_app(self, repo_path: str) -> bool:
        """Check if repository contains a Python application"""
        python_files = ['requirements.txt', 'setup.py', 'pyproject.toml', 'Pipfile']
        
        # Check in root directory
        if any(os.path.exists(os.path.join(repo_path, f)) for f in python_files):
            return True
            
        # Check in common subdirectories
        subdirs = ['app', 'src', 'server', 'backend']
        for subdir in subdirs:
            subdir_path = os.path.join(repo_path, subdir)
            if os.path.exists(subdir_path):
                if any(os.path.exists(os.path.join(subdir_path, f)) for f in python_files):
                    return True
                    
        # Check for .py files recursively
        for root, dirs, files in os.walk(repo_path):
            if any(f.endswith('.py') for f in files):
                return True
                
        return False
    
    def _is_nodejs_app(self, repo_path: str) -> bool:
        """Check if repository contains a Node.js application"""
        return os.path.exists(os.path.join(repo_path, 'package.json'))
    
    def _is_java_app(self, repo_path: str) -> bool:
        """Check if repository contains a Java application"""
        java_files = ['pom.xml', 'build.gradle', 'gradle.properties']
        return any(os.path.exists(os.path.join(repo_path, f)) for f in java_files)
    
    def _is_php_app(self, repo_path: str) -> bool:
        """Check if repository contains a PHP application"""
        php_files = ['composer.json', 'composer.lock']
        return any(os.path.exists(os.path.join(repo_path, f)) for f in php_files)
    
    def _analyze_python_app(self, repo_path: str) -> Dict:
        """Analyze Python application"""
        analysis = {'language': 'python', 'framework': None}
        
        # Find the actual application directory
        app_dir = repo_path
        subdirs_to_check = ['', 'app', 'src', 'server', 'backend']
        
        # Check for requirements.txt and determine app directory
        for subdir in subdirs_to_check:
            current_dir = os.path.join(repo_path, subdir) if subdir else repo_path
            req_file = os.path.join(current_dir, 'requirements.txt')
            
            if os.path.exists(req_file):
                app_dir = current_dir
                with open(req_file, 'r') as f:
                    analysis['dependencies'] = [line.strip().split('==')[0].split('>=')[0].split('<=')[0] 
                                              for line in f if line.strip() and not line.startswith('#')]
                break
        
        # Determine framework by checking for specific files
        framework_indicators = {
            'flask': ['app.py', 'main.py', 'wsgi.py'],
            'django': ['manage.py', 'settings.py'],
            'fastapi': ['main.py', 'app.py'],
            'bottle': ['app.py', 'main.py']
        }
        
        # Check dependencies first for framework hints
        deps_lower = [dep.lower() for dep in analysis.get('dependencies', [])]
        if 'flask' in deps_lower:
            analysis['framework'] = 'flask'
        elif 'django' in deps_lower:
            analysis['framework'] = 'django'
        elif 'fastapi' in deps_lower:
            analysis['framework'] = 'fastapi'
        elif 'bottle' in deps_lower:
            analysis['framework'] = 'bottle'
        
        # If framework not detected from dependencies, check files
        if not analysis['framework']:
            for framework, indicators in framework_indicators.items():
                for subdir in subdirs_to_check:
                    current_dir = os.path.join(repo_path, subdir) if subdir else repo_path
                    if any(os.path.exists(os.path.join(current_dir, indicator)) for indicator in indicators):
                        analysis['framework'] = framework
                        app_dir = current_dir
                        break
                if analysis['framework']:
                    break
        
        # Determine start command based on framework and directory structure
        relative_path = os.path.relpath(app_dir, repo_path) if app_dir != repo_path else ""
        
        if analysis['framework'] == 'flask':
            if relative_path and relative_path != ".":
                analysis['start_commands'] = [f'cd {relative_path} && python app.py', f'cd {relative_path} && flask run']
            else:
                analysis['start_commands'] = ['python app.py', 'flask run']
            analysis['port'] = 5000
        elif analysis['framework'] == 'django':
            if relative_path and relative_path != ".":
                analysis['start_commands'] = [f'cd {relative_path} && python manage.py runserver 0.0.0.0:8000']
            else:
                analysis['start_commands'] = ['python manage.py runserver 0.0.0.0:8000']
            analysis['port'] = 8000
        elif analysis['framework'] == 'fastapi':
            if relative_path and relative_path != ".":
                analysis['start_commands'] = [f'cd {relative_path} && uvicorn main:app --host 0.0.0.0 --port 8000']
            else:
                analysis['start_commands'] = ['uvicorn main:app --host 0.0.0.0 --port 8000']
            analysis['port'] = 8000
        else:
            # Default Python app
            if relative_path and relative_path != ".":
                analysis['start_commands'] = [f'cd {relative_path} && python app.py']
            else:
                analysis['start_commands'] = ['python app.py']
            analysis['port'] = 5000
        
        return analysis
    
    def _analyze_nodejs_app(self, repo_path: str) -> Dict:
        """Analyze Node.js application"""
        analysis = {'language': 'nodejs', 'framework': None}
        
        package_json = os.path.join(repo_path, 'package.json')
        if os.path.exists(package_json):
            with open(package_json, 'r') as f:
                package_data = json.load(f)
                
                # Get dependencies
                analysis['dependencies'] = list(package_data.get('dependencies', {}).keys())
                
                # Determine framework
                if 'express' in analysis['dependencies']:
                    analysis['framework'] = 'express'
                elif 'next' in analysis['dependencies']:
                    analysis['framework'] = 'nextjs'
                elif 'react' in analysis['dependencies']:
                    analysis['framework'] = 'react'
                elif 'vue' in analysis['dependencies']:
                    analysis['framework'] = 'vue'
                
                # Get start commands
                scripts = package_data.get('scripts', {})
                if 'start' in scripts:
                    analysis['start_commands'] = [f"npm start", f"node {scripts['start']}"]
                elif 'dev' in scripts:
                    analysis['start_commands'] = [f"npm run dev"]
                
                analysis['port'] = 3000
        
        return analysis
    
    def _analyze_java_app(self, repo_path: str) -> Dict:
        """Analyze Java application"""
        analysis = {'language': 'java', 'framework': None}
        
        # Check for Maven
        if os.path.exists(os.path.join(repo_path, 'pom.xml')):
            analysis['framework'] = 'maven'
            analysis['build_commands'] = ['mvn clean install']
            analysis['start_commands'] = ['java -jar target/*.jar']
            analysis['port'] = 8080
        
        # Check for Gradle
        elif os.path.exists(os.path.join(repo_path, 'build.gradle')):
            analysis['framework'] = 'gradle'
            analysis['build_commands'] = ['./gradlew build']
            analysis['start_commands'] = ['java -jar build/libs/*.jar']
            analysis['port'] = 8080
        
        return analysis
    
    def _analyze_php_app(self, repo_path: str) -> Dict:
        """Analyze PHP application"""
        analysis = {'language': 'php', 'framework': None}
        
        composer_json = os.path.join(repo_path, 'composer.json')
        if os.path.exists(composer_json):
            with open(composer_json, 'r') as f:
                composer_data = json.load(f)
                
                # Determine framework
                if 'laravel/laravel' in composer_data.get('require', {}):
                    analysis['framework'] = 'laravel'
                elif 'symfony/symfony' in composer_data.get('require', {}):
                    analysis['framework'] = 'symfony'
                
                analysis['start_commands'] = ['php -S 0.0.0.0:8000']
                analysis['port'] = 8000
        
        return analysis


class InfrastructureDecisionEngine:
    """Determines the best infrastructure strategy for deployment"""
    
    def __init__(self):
        self.deployment_strategies = {
            'simple': {
                'description': 'Single VM deployment',
                'terraform_template': 'simple_vm',
                'suitable_for': ['flask', 'express', 'django', 'fastapi', 'laravel']
            },
            'containerized': {
                'description': 'Docker container deployment',
                'terraform_template': 'docker_vm',
                'suitable_for': ['react', 'vue', 'nextjs', 'spring']
            },
            'serverless': {
                'description': 'Serverless function deployment',
                'terraform_template': 'lambda',
                'suitable_for': ['fastapi', 'express']
            }
        }
    
    def determine_strategy(self, analysis: Dict, requirements: Dict) -> Dict:
        """Determine the best deployment strategy"""
        framework = analysis.get('framework')
        language = analysis.get('language')
        
        # Default to simple VM deployment
        strategy = 'simple'
        
        # Choose containerized for frontend frameworks
        if framework in ['react', 'vue', 'nextjs']:
            strategy = 'containerized'
        
        # Choose serverless for lightweight APIs
        elif framework in ['fastapi', 'express'] and analysis.get('dependencies', []):
            if len(analysis['dependencies']) < 10:  # Simple dependencies
                strategy = 'serverless'
        
        return {
            'strategy': strategy,
            'template': self.deployment_strategies[strategy]['terraform_template'],
            'description': self.deployment_strategies[strategy]['description']
        }


class TerraformManager:
    """Manages Terraform infrastructure provisioning"""
    
    def __init__(self):
        self.terraform_dir = "terraform"
        self.templates_dir = "terraform_templates"
        
    def create_terraform_config(self, strategy: str, analysis: Dict, requirements: Dict) -> str:
        """Create Terraform configuration for deployment"""
        os.makedirs(self.terraform_dir, exist_ok=True)
        
        # Create main.tf
        main_tf = self._generate_main_tf(strategy, analysis, requirements)
        with open(os.path.join(self.terraform_dir, 'main.tf'), 'w') as f:
            f.write(main_tf)
        
        # Create variables.tf
        variables_tf = self._generate_variables_tf(requirements)
        with open(os.path.join(self.terraform_dir, 'variables.tf'), 'w') as f:
            f.write(variables_tf)
        
        # Create outputs.tf
        outputs_tf = self._generate_outputs_tf()
        with open(os.path.join(self.terraform_dir, 'outputs.tf'), 'w') as f:
            f.write(outputs_tf)
        
        return self.terraform_dir
    
    def _generate_main_tf(self, strategy: str, analysis: Dict, requirements: Dict) -> str:
        """Generate main.tf content"""
        provider = requirements.get('provider', 'aws').lower()
        
        if provider == 'aws':
            return self._generate_aws_main_tf(strategy, analysis)
        elif provider == 'gcp':
            return self._generate_gcp_main_tf(strategy, analysis)
        else:
            raise Exception(f"Unsupported provider: {provider}")
    
    def _generate_aws_main_tf(self, strategy: str, analysis: Dict) -> str:
        """Generate AWS main.tf"""
        return f"""
terraform {{
  required_providers {{
    aws = {{
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }}
  }}
}}

provider "aws" {{
  region = var.aws_region
}}

# Security Group
resource "aws_security_group" "app_sg" {{
  name        = "app-security-group"
  description = "Security group for application"

  ingress {{
    from_port   = {analysis.get('port', 80)}
    to_port     = {analysis.get('port', 80)}
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }}

  ingress {{
    from_port   = 22
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }}

  egress {{
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }}
}}

# EC2 Instance
resource "aws_instance" "app_server" {{
  ami           = var.ami_id
  instance_type = var.instance_type
  key_name      = var.key_name

  security_groups = [aws_security_group.app_sg.name]

  user_data = <<-EOF
              #!/bin/bash
              yum update -y
              yum install -y git docker
              systemctl start docker
              systemctl enable docker
              
              # Install application dependencies
              {self._generate_user_data(analysis)}
              
              # Start application
              {self._generate_start_script(analysis)}
              EOF

  tags = {{
    Name = "arvo-app-server"
  }}
}}

# Elastic IP
resource "aws_eip" "app_eip" {{
  instance = aws_instance.app_server.id
  domain   = "vpc"
}}
"""
    
    def _generate_gcp_main_tf(self, strategy: str, analysis: Dict) -> str:
        """Generate GCP main.tf"""
        return f"""
terraform {{
  required_providers {{
    google = {{
      source  = "hashicorp/google"
      version = "~> 4.0"
    }}
  }}
}}

provider "google" {{
  project = var.gcp_project
  region  = var.gcp_region
}}

# Compute Instance
resource "google_compute_instance" "app_server" {{
  name         = "arvo-app-server"
  machine_type = var.machine_type
  zone         = var.gcp_zone

  boot_disk {{
    initialize_params {{
      image = var.gcp_image
    }}
  }}

  network_interface {{
    network = "default"
    access_config {{
      // Ephemeral public IP
    }}
  }}

  metadata_startup_script = <<-EOF
              #!/bin/bash
              apt-get update
              apt-get install -y git docker.io
              systemctl start docker
              systemctl enable docker
              
              # Install application dependencies
              {self._generate_user_data(analysis)}
              
              # Start application
              {self._generate_start_script(analysis)}
              EOF
}}

# Firewall Rule
resource "google_compute_firewall" "app_firewall" {{
  name    = "app-firewall"
  network = "default"

  allow {{
    protocol = "tcp"
    ports    = ["{analysis.get('port', 80)}", "22"]
  }}

  source_ranges = ["0.0.0.0/0"]
}}
"""
    
    def _generate_variables_tf(self, requirements: Dict) -> str:
        """Generate variables.tf"""
        provider = requirements.get('provider', 'aws').lower()
        
        if provider == 'aws':
            return """
variable "aws_region" {
  description = "AWS region"
  type        = string
  default     = "us-east-1"
}

variable "ami_id" {
  description = "AMI ID for the instance"
  type        = string
  default     = "ami-0c55b159cbfafe1f0"
}

variable "instance_type" {
  description = "Instance type"
  type        = string
  default     = "t2.micro"
}

variable "key_name" {
  description = "Name of the key pair"
  type        = string
  default     = "arvo-key"
}
"""
        else:
            return """
variable "gcp_project" {
  description = "GCP project ID"
  type        = string
}

variable "gcp_region" {
  description = "GCP region"
  type        = string
  default     = "us-central1"
}

variable "gcp_zone" {
  description = "GCP zone"
  type        = string
  default     = "us-central1-a"
}

variable "machine_type" {
  description = "Machine type"
  type        = string
  default     = "e2-micro"
}

variable "gcp_image" {
  description = "GCP image"
  type        = string
  default     = "debian-cloud/debian-11"
}
"""
    
    def _generate_outputs_tf(self) -> str:
        """Generate outputs.tf"""
        return """
output "public_ip" {
  description = "Public IP of the instance"
  value       = aws_eip.app_eip.public_ip
}

output "instance_id" {
  description = "Instance ID"
  value       = aws_instance.app_server.id
}
"""
    
    def _generate_user_data(self, analysis: Dict) -> str:
        """Generate user data script for application setup"""
        language = analysis.get('language')
        
        if language == 'python':
            return """
# Install Python
yum install -y python3 python3-pip
pip3 install --upgrade pip

# Install application dependencies
if [ -f requirements.txt ]; then
    pip3 install -r requirements.txt
fi
if [ -f app/requirements.txt ]; then
    pip3 install -r app/requirements.txt
fi
"""
        elif language == 'nodejs':
            return """
# Install Node.js
curl -fsSL https://rpm.nodesource.com/setup_18.x | bash -
yum install -y nodejs

# Install application dependencies
if [ -f package.json ]; then
    npm install
fi
"""
        elif language == 'java':
            return """
# Install Java
yum install -y java-11-openjdk

# Install Maven
yum install -y maven
"""
        else:
            return "# Default setup"
    
    def _generate_start_script(self, analysis: Dict) -> str:
        """Generate start script for the application"""
        start_commands = analysis.get('start_commands', [])
        if start_commands:
            return f"""
# Start application
cd /home/ec2-user
{' '.join(start_commands)} &
"""
        return "# No start commands defined"
    
    def deploy(self, terraform_dir: str, demo_mode: bool = False) -> Dict:
        """Deploy infrastructure using Terraform"""
        if demo_mode:
            # Demo mode - simulate deployment without actually running terraform
            return {
                'success': True,
                'public_ip': '52.23.45.67',  # Mock IP for demo
                'instance_id': 'i-1234567890abcdef0',  # Mock instance ID
                'message': 'Demo deployment completed (no actual resources created)'
            }
        
        try:
            # Initialize Terraform
            subprocess.run(['terraform', 'init'], cwd=terraform_dir, check=True)
            
            # Plan deployment
            subprocess.run(['terraform', 'plan'], cwd=terraform_dir, check=True)
            
            # Apply deployment
            subprocess.run(['terraform', 'apply', '-auto-approve'], cwd=terraform_dir, check=True)
            
            # Get outputs
            result = subprocess.run(['terraform', 'output', '-json'], 
                                  cwd=terraform_dir, capture_output=True, text=True, check=True)
            outputs = json.loads(result.stdout)
            
            return {
                'success': True,
                'public_ip': outputs.get('public_ip', {}).get('value'),
                'instance_id': outputs.get('instance_id', {}).get('value')
            }
            
        except subprocess.CalledProcessError as e:
            return {
                'success': False,
                'error': f"Terraform deployment failed: {e}"
            }


class CodeModifier:
    """Modifies application code for cloud deployment"""
    
    def __init__(self):
        self.localhost_patterns = [
            r'localhost:\d+',
            r'127\.0\.0\.1:\d+',
            r'http://localhost',
            r'https://localhost'
        ]
    
    def modify_code_for_deployment(self, repo_path: str, public_ip: str, analysis: Dict) -> List[str]:
        """Modify code for cloud deployment"""
        modified_files = []
        
        # Find and modify files with localhost references
        for root, dirs, files in os.walk(repo_path):
            for file in files:
                if file.endswith(('.py', '.js', '.json', '.env', '.yml', '.yaml')):
                    file_path = os.path.join(root, file)
                    if self._modify_file(file_path, public_ip):
                        modified_files.append(file_path)
        
        return modified_files
    
    def _modify_file(self, file_path: str, public_ip: str) -> bool:
        """Modify a single file to replace localhost with public IP"""
        try:
            with open(file_path, 'r') as f:
                content = f.read()
            
            original_content = content
            
            # Replace localhost patterns
            for pattern in self.localhost_patterns:
                if 'localhost' in pattern:
                    content = re.sub(pattern, f'{public_ip}', content)
                else:
                    content = re.sub(pattern, f'http://{public_ip}', content)
            
            # Write back if modified
            if content != original_content:
                with open(file_path, 'w') as f:
                    f.write(content)
                return True
            
            return False
            
        except Exception as e:
            print(f"Warning: Could not modify {file_path}: {e}")
            return False


class ArvoAI:
    """Main ArvoAI autodeployment system"""
    
    def __init__(self):
        self.name = "ArvoAI"
        self.version = "1.0.0"
        self.analyzer = RepositoryAnalyzer()
        self.decision_engine = InfrastructureDecisionEngine()
        self.terraform_manager = TerraformManager()
        self.code_modifier = CodeModifier()
        self.conversation_history = []
        
        # Setup logging
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('arvo_deployment.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def _should_use_demo_mode(self) -> bool:
        """Check if we should use demo mode (no AWS credentials available)"""
        # Check for AWS credentials in environment variables
        aws_access_key = os.environ.get('AWS_ACCESS_KEY_ID')
        aws_secret_key = os.environ.get('AWS_SECRET_ACCESS_KEY')
        
        # Check for AWS profile
        aws_profile = os.environ.get('AWS_PROFILE')
        
        # Check for AWS credentials file
        aws_creds_file = os.path.expanduser('~/.aws/credentials')
        has_creds_file = os.path.exists(aws_creds_file)
        
        # If any credentials are found, don't use demo mode
        if aws_access_key and aws_secret_key:
            return False
        if aws_profile:
            return False
        if has_creds_file:
            return False
        
        # No credentials found, use demo mode
        return True
    
    def parse_natural_language(self, user_input: str) -> Dict:
        """Parse natural language input to extract deployment requirements"""
        requirements = {
            'provider': 'aws',  # default
            'region': None,
            'instance_type': None,
            'framework': None
        }
        
        user_input_lower = user_input.lower()
        
        # Extract cloud provider
        if 'aws' in user_input_lower or 'amazon' in user_input_lower:
            requirements['provider'] = 'aws'
        elif 'gcp' in user_input_lower or 'google' in user_input_lower:
            requirements['provider'] = 'gcp'
        
        # Extract framework mentions
        frameworks = ['flask', 'django', 'fastapi', 'express', 'react', 'vue', 'spring', 'laravel']
        for framework in frameworks:
            if framework in user_input_lower:
                requirements['framework'] = framework
                break
        
        # Extract region mentions
        regions = ['us-east-1', 'us-west-2', 'eu-west-1', 'ap-southeast-1']
        for region in regions:
            if region in user_input_lower:
                requirements['region'] = region
                break
        
        return requirements
    
    def deploy_application(self, repo_url: str, requirements: Dict) -> Dict:
        """Main deployment orchestration method"""
        try:
            self.logger.info("Starting deployment process...")
            
            # Step 1: Download and analyze repository
            self.logger.info("Downloading and analyzing repository...")
            repo_path = self.analyzer.download_repository(repo_url)
            analysis = self.analyzer.analyze_repository(repo_path)
            
            self.logger.info(f"Analysis complete: {analysis}")
            
            # Step 2: Determine deployment strategy
            self.logger.info("Determining deployment strategy...")
            strategy = self.decision_engine.determine_strategy(analysis, requirements)
            
            self.logger.info(f"Selected strategy: {strategy}")
            
            # Step 3: Create Terraform configuration
            self.logger.info("Creating Terraform configuration...")
            terraform_dir = self.terraform_manager.create_terraform_config(
                strategy['template'], analysis, requirements
            )
            
            # Step 4: Deploy infrastructure
            self.logger.info("Deploying infrastructure...")
            
            # Check if AWS credentials are available
            demo_mode = True 
            if demo_mode:
                self.logger.info("AWS credentials not found - using demo mode")
            
            deployment_result = self.terraform_manager.deploy(terraform_dir, demo_mode=demo_mode)
            
            if not deployment_result['success']:
                raise Exception(deployment_result['error'])
            
            public_ip = deployment_result['public_ip']
            if demo_mode:
                self.logger.info(f"Demo deployment completed. Mock Public IP: {public_ip}")
            else:
                self.logger.info(f"Infrastructure deployed successfully. Public IP: {public_ip}")
            
            # Step 5: Modify code for deployment
            self.logger.info("Modifying code for cloud deployment...")
            modified_files = self.code_modifier.modify_code_for_deployment(
                repo_path, public_ip, analysis
            )
            
            self.logger.info(f"Modified {len(modified_files)} files for deployment")
            
            # Step 6: Return deployment information
            return {
                'success': True,
                'public_ip': public_ip,
                'instance_id': deployment_result['instance_id'],
                'analysis': analysis,
                'strategy': strategy,
                'modified_files': modified_files,
                'application_url': f"http://{public_ip}:{analysis.get('port', 80)}"
            }
            
        except Exception as e:
            self.logger.error(f"Deployment failed: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def print_welcome(self):
        """Display welcome message"""
        print(f"\n{'='*60}")
        print(f"üöÄ Welcome to {self.name} v{self.version}")
        print(f"{'='*60}")
        print("I'm here to automatically deploy your applications!")
        print("\nWhat I can do:")
        print("‚Ä¢ Analyze your repository and detect application type")
        print("‚Ä¢ Determine the best deployment strategy")
        print("‚Ä¢ Provision cloud infrastructure with Terraform")
        print("‚Ä¢ Deploy your application automatically")
        print("‚Ä¢ Update your code for cloud deployment")
        print("\nJust describe your deployment needs and provide a repository!")
        print("Type 'exit' or 'bye' to quit the session.")
        print(f"{'='*60}\n")
    
    def get_user_input(self) -> str:
        """Get user input"""
        try:
            return input("You: ").strip()
        except KeyboardInterrupt:
            print("\n\nGoodbye! üëã")
            sys.exit(0)
    
    def process_deployment_request(self, user_input: str) -> str:
        """Process deployment request from user input"""
        # Extract repository URL from input
        repo_url = None
        words = user_input.split()
        for i, word in enumerate(words):
            if 'github.com' in word or word.endswith('.zip'):
                repo_url = word
                break
        
        if not repo_url:
            return "Please provide a GitHub repository URL or zip file path. For example:\n" \
                   "'Deploy this flask app on AWS: https://github.com/user/repo'"
        
        # Parse natural language requirements
        requirements = self.parse_natural_language(user_input)
        
        # Start deployment
        self.logger.info(f"Starting deployment for: {repo_url}")
        deployment_result = self.deploy_application(repo_url, requirements)
        
        if deployment_result['success']:
            return f"üéâ Deployment successful!\n\n" \
                   f"üìä Analysis: {deployment_result['analysis']['framework']} application\n" \
                   f"üåê Public IP: {deployment_result['public_ip']}\n" \
                   f"üîó Application URL: {deployment_result['application_url']}\n" \
                   f"üìù Modified {len(deployment_result['modified_files'])} files\n" \
                   f"üìã Instance ID: {deployment_result['instance_id']}\n\n" \
                   f"Your application is now live! üöÄ"
        else:
            return f"‚ùå Deployment failed: {deployment_result['error']}\n\n" \
                   f"Please check the logs for more details."
    
    def run(self):
        """Main chat loop"""
        self.print_welcome()
        
        while True:
            try:
                user_input = self.get_user_input()
                
                if user_input.lower() in ['exit', 'bye', 'quit', 'goodbye', 'stop']:
                    print(f"\n{self.name}: Thanks for using {self.name}! üëã")
                    break
                
                if not user_input:
                    continue
                
                # Process deployment request
                response = self.process_deployment_request(user_input)
                print(f"\n{self.name}: {response}\n")
                
            except Exception as e:
                print(f"\n{self.name}: Sorry, I encountered an error: {e}")
                print("Please try again or type 'exit' to quit.\n")


def main():
    """Main entry point"""
    try:
        arvo = ArvoAI()
        arvo.run()
    except KeyboardInterrupt:
        print("\n\nGoodbye! üëã")
        sys.exit(0)
    except Exception as e:
        print(f"Fatal error: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
